{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eba78ef",
   "metadata": {},
   "source": [
    "# Geometric blueprint\n",
    "#### NORA Summer School 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41965e8",
   "metadata": {},
   "source": [
    "## Overall structure\n",
    "\n",
    "* Repetition from yeasterday.\n",
    "* Invariance, equivariance and smoothning operator.\n",
    "* Convolutions\n",
    "* The geometric bluprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b38506",
   "metadata": {},
   "source": [
    "### Repetition: groups\n",
    "\n",
    "**A group** is a set $G$ with a binary operation $G \\times G \\to G$, $g \\cdot h$ such that\n",
    "1. Closed: If $g,h \\in G$, then $g \\cdot h \\in G$.\n",
    "2. Associativity: For $g,h, k \\in G$,\n",
    "$$(g \\cdot h) \\cdot k = g\\cdot (h \\cdot k).$$\n",
    "3. Identity: There is an element $1 \\in G$ such that\n",
    "$$1 \\cdot g = g \\cdot 1 = g.$$\n",
    "4. Inverse: For any element $g \\in G$, there is an element $g^{-1} \\in G$ such that\n",
    "$$g \\cdot g^{-1} = g^{-1} \\cdot g.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d20bd7",
   "metadata": {},
   "source": [
    "### Repetition: Group action\n",
    "\n",
    "A group action $\\rho$ is a map $\\rho: G \\times \\Omega \\times \\Omega$,\n",
    "$$g, \\omega \\mapsto \\rho(g)\\omega, \\qquad \\text{also written just} \\qquad g \\cdot \\omega.$$\n",
    "such that\n",
    "$$\\rho(g) \\rho(h)\\omega = \\rho(gh) \\omega \\qquad \\rho(1)\\omega = \\omega.$$\n",
    "\n",
    "We can consider $\\rho(g)$ as a map from $\\Omega \\to \\Omega$. Note that from the previous assumptions\n",
    "$$\\rho(g^{-1}) = \\rho(g)^{-1}.$$\n",
    "If $\\Omega=\\mathcal{V}$ is a vector space, then a group action $\\rho$ of $G$ on $\\mathcal{V}$ such that $\\rho(g)$ is always a linear map is called **a representation**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e1b953",
   "metadata": {},
   "source": [
    "## Invariance and equivariance\n",
    "\n",
    "Let $\\rho$ be a group action of a group $G$ on $\\Omega$. Consider a space of signals $\\mathcal{X}: \\Omega \\to \\mathcal{V}$. Recall that we have a representation of $G$ on $\\mathcal{X}(\\Omega)$ given by\n",
    "$$(\\rho(g) x)(\\omega) = x(\\rho(g^{-1})\\omega).$$\n",
    "\n",
    "\n",
    "We call the function $f:\\mathcal{X}(\\Omega) \\to \\mathcal{W}$ **invariant** (relative to $\\rho$) if\n",
    "$$f(\\rho(g)x) = f(x), \\qquad \\text{for any g \\in G}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dad6380",
   "metadata": {},
   "source": [
    "<span style=\"font-size:24px; color:blue\">\n",
    "Exercises: \n",
    "    We are going to look at several different examples. Identify the symmetry group of the problem. Explain if we want $f$ to be invariant or equivariant and why.\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401c3287",
   "metadata": {},
   "source": [
    "**Example:** $\\Omega = C_{28} \\times C_{28}$, $\\mathcal{X}(\\Omega) =\\{ f: \\Omega \\to \\mathbb{R}\\}$ scans of hand-drawn integers, grayscale. $f(img)$ gives me the probability for each integer $0,1,\\dots,9$.\n",
    "$$f:\\mathcal{X}(\\Omega) \\to \\mathbb{R}^{\\text{range}(10)} = \\mathbb{R}^{10}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eac57c2",
   "metadata": {},
   "source": [
    "**Example:** $\\Omega = C_m \\times C_n$, $\\mathcal{X}(\\Omega) = \\{ x:\\Omega \\to \\mathbb{R}^3 \\}$ color images of faces. $f(img1,img2)$ gives us the probability of two images being of the same person\n",
    "    $$f: \\mathcal{X}(\\Omega) \\times \\mathcal{X}(\\Omega) \\to \\mathbb{R}^{\\{True, False \\}} = \\mathbb{R}^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3a311f",
   "metadata": {},
   "source": [
    "**Example:** With stereo images of 3d-shapes, we want to classify them into $N$ classes of objects, so we have\n",
    "$$f(imgLeft, imgRight) \\qquad \\text{gives a vector in } \\mathbb{R}^N.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2423e9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a28820a",
   "metadata": {},
   "source": [
    "## How do we get invariance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42039370",
   "metadata": {},
   "source": [
    "### Approach 1: Data-agmentation.\n",
    "If $\\{ input,label\\}$ is in our training set, then we also add $\\{ \\rho(g)input, label\\}$ to the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c38541",
   "metadata": {},
   "source": [
    "Advantage:\n",
    "* Easy to implement.\n",
    "\n",
    "Disadvantage:\n",
    "* Larger set of training data. slower training, in particular if the group is large.\n",
    "* No guarantee that the final model will be invariant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6732217",
   "metadata": {},
   "source": [
    "### Approach 2: Smoothning model.\n",
    "We can force a model or any function to be invariant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a246a65",
   "metadata": {},
   "source": [
    "**Theorem: Smoothning operator.** If $\\rho$ is the group action $\\rho(g)x = g \\cdot x$ of some finite group $G$ on $\\mathcal{X}(\\Omega)$ and $f:\\Omega \\to \\mathcal{W}$ is any function, then\n",
    "$$F(x) = S_{G}f(x) = \\frac{1}{|G|}\\sum_{g \\in G} f(g \\cdot x),$$\n",
    "is invariant. Furthermore, if $f$ is invariant, then $S_G f = f$. Here, $|G|$ is the number of elements in the groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0d48c3",
   "metadata": {},
   "source": [
    "*Proof:* Let $h \\in G$ be any group element. Recall that for a group action, we have\n",
    "$$\\rho(g\\cdot h)x = \\rho(g) \\rho(h) x, \\qquad \\text{which can also be written as } (g \\cdot h) \\cdot x = g \\cdot (h \\cdot x).$$\n",
    "We use this property by\n",
    "\\begin{align*}\n",
    "F(h \\cdot x) & = \\frac{1}{|G|} \\sum_{g \\in G} f(g \\cdot (h \\cdot x)) =  \\frac{1}{|G|} \\sum_{g \\in G} f((g \\cdot h) \\cdot x) \\\\\n",
    "& = \\frac{1}{|G|} \\sum_{g \\cdot h^{-1} \\in G} f(g \\cdot x)  = \\frac{1}{|G|} \\sum_{g \\in G} f(g \\cdot x) = F(x)\n",
    "\\end{align*}\n",
    "Here we have used that $g \\mapsto g \\cdot h^{-1}$ is a one-to-one correspondence between elements in $G$.\n",
    "\n",
    "Finanlly, if $f(g\\cdot x)= f(x)$ for any $g \\in G$, then\n",
    "$$\\frac{1}{|G|} \\sum_{g\\in G} f(g \\cdot x) = \\frac{1}{|G|} \\sum_{g \\in G} f(x) = \\frac{1}{|G|} |G|f(x) = f(x). \\qquad \\qquad \\Box$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acafc651",
   "metadata": {},
   "source": [
    "**Example:** Consider the function\n",
    "    $$f(x[0],x[1],x[2])= x[0]^2 + x[1]+ x[1]\\cdot x[2]+ 1.$$\n",
    "Assume that we want this\n",
    "\n",
    "\n",
    "We have the group $S_3$ of permutations. Suppose we want our function to be invariant under permutations.\n",
    "$S_3$ has 6 elements (3!). $(), (01), (02), (12), (012), (021)$. We compute the smoothning operator\n",
    "\n",
    "\\begin{align*}\n",
    "Sf(x[0],x[1],x[2]) &  = \\frac{1}{6} \\left( f(x[0],x[1],x[2]) + f(x[1],x[0],x[2])+ f(x[2],x[1],x[1]) \\right. \\\\\n",
    "& \\qquad  \\left. +f(x[0],x[2],x[1]) + f(x[2],x[0],x[1])+ f(x[1],x[2],x[0]) \\right) \\\\\n",
    "& = \\frac{1}{3}\\left(x[0]^2+x[1]^2 + x[2]^2 \\right)+ \\frac{1}{3}(x[0] +x[1]+x[2]) \\\\\n",
    "& \\qquad +\\frac{1}{3}\\left(x[0]x[1]+x[0]x[2]+x[1]x[2]\\right) +1\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c52f28b",
   "metadata": {},
   "source": [
    "**For a neural network: Let us go to the MNIST file and check**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb4682c",
   "metadata": {},
   "source": [
    "Can also force equivariance. If $F: \\mathcal{X} \\to \\mathcal{Y}$ is a function, then\n",
    "$$S_GF(x) =\\frac{1}{|G|} \\sum_{g \\in G}\\rho_{\\mathcal{Y}}(g^{-1})F(\\rho_{\\mathcal{X}}(g) x)$$\n",
    "will be equivariant.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca14710",
   "metadata": {},
   "source": [
    "**Example: Convolution** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf763ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce2a5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    plt.imshow(img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e24192",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We have a convolution filert\n",
    "Filter = np.array([[0,-1,10,-1,0],[0,0,-1,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]]) # Sharpens and moves 5 pixels up\n",
    "Filter = np.zeros([201,201])\n",
    "Filter[0,100]=10\n",
    "Filter[0,99]=-1\n",
    "Filter[0,101]=-1\n",
    "Filter[1,100]=-1\n",
    "\n",
    "# Import image\n",
    "I = cv2.imread(\"barbara.bmp\",cv2.IMREAD_GRAYSCALE).astype(np.float32)\n",
    "\n",
    "\n",
    "# Function that moves down and sharpens\n",
    "def F(image):\n",
    "     return cv2.filter2D(src=image, ddepth=-1, kernel=Filter)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11e0f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2)\n",
    "\n",
    "axs[0,0].imshow(I, cmap=\"gray\")\n",
    "axs[0,1].imshow(I, cmap=\"gray\")\n",
    "\n",
    "J10 = F(I)\n",
    "J11 = cv2.rotate(I, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "\n",
    "axs[1,0].imshow(J10, cmap=\"gray\")\n",
    "axs[1,1].imshow(J11, cmap=\"gray\")\n",
    "\n",
    "\n",
    "J20 = cv2.rotate(J10, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "J21 = F(J11)\n",
    "\n",
    "axs[2,0].imshow(J20, cmap=\"gray\")\n",
    "axs[2,1].imshow(J21, cmap=\"gray\")\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# First colum, convolution, then rotate, second column, rotate, then convolution.\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af685ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us use p4: Group of rotations: R_0, R_90, R_180, R_270\n",
    "# We define the following smoothing operator\n",
    "\n",
    "def Smoothp4(f,img):\n",
    "    J = img.copy()\n",
    "    K = f(J)\n",
    "    \n",
    "    J90 = cv2.rotate(J, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "    K90 =cv2.rotate(f(J90).copy(), cv2.ROTATE_90_CLOCKWISE)\n",
    "    \n",
    "    J180 = cv2.rotate(J.copy(), cv2.ROTATE_180)\n",
    "    K180 =cv2.rotate(f(J180), cv2.ROTATE_180)\n",
    "    \n",
    "    J270 = cv2.rotate(J.copy(), cv2.ROTATE_90_CLOCKWISE)\n",
    "    K270 = cv2.rotate(f(J270), cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "    \n",
    "    return (K+K90+ K180+ K270)/4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545e4456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivariant image, commute with rotation.\n",
    "imshow(Smoothp4(F,I))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf2d466",
   "metadata": {},
   "source": [
    "*Remark* We can also do the same with an infinite group if we replace the sum with an appropriate integral. Ex: Rotation group\n",
    "$$S_{Rotation}f(x) = \\frac{1}{2\\pi} \\int_0^{2\\pi} f(R_\\theta \\cdot x) d\\theta, \\qquad \\text{$R_\\theta$ rotation by $\\theta$}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77893aa",
   "metadata": {},
   "source": [
    "#### Smoothning operators and error terms\n",
    "Recall: if $f^*$ is the optimal function and $f$ is the model we find then\n",
    "$$TrueLoss(f^*,f) \\leq \\varepsilon_{class}+\\varepsilon_{approx}+\\varepsilon_{opt}+\\varepsilon_{stat}.$$\n",
    "* $\\varepsilon_{class}$: our target function might not be in our class.\n",
    "* $\\varepsilon_{approx}$: We can only optimize for a subset of our class.\n",
    "* $\\varepsilon_{opt}$: We may not find the best function in the subset where we are optimizing.\n",
    "* $\\varepsilon_{stat}$: We can only optimize for the loss in our training data.\n",
    "\n",
    "The smoothing operator does not affect the approximation error if the function we are trying to find is invariant\n",
    "$$\\inf_{f \\in \\mathcal{F}} \\| f- f^*\\|^2 = \\inf_{f \\in S_G \\mathcal{F}} \\| f- f^*\\|^2.$$\n",
    "Why? Orthogonal projection to the subspace of invariant functions.\n",
    "$$\\|f -f^*\\|^2 = \\| S_G f - S_G f^*\\|^2 + \\| (\\mathrm{id}- S_G) f - (\\mathrm{id}-S_G) f^*\\|^2= \\| S_G f - f^*\\|^2 + \\| (\\mathrm{id}- S_G) f \\|^2.$$\n",
    "Reduces statistical error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efca4aa2",
   "metadata": {},
   "source": [
    "### Approach 3: Make the network itself invariant\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7c85cb",
   "metadata": {},
   "source": [
    "Which is what we will look more at now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882fa0c5",
   "metadata": {},
   "source": [
    "# The Geometric Deep Learning blue-print"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee6fd5b",
   "metadata": {},
   "source": [
    "![GDL blueprint](https://miro.medium.com/v2/resize:fit:1400/1*VEujtuj-gSaLdGu4S3b6xg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264cf7a4",
   "metadata": {},
   "source": [
    "Idea: If we have a sequence of maps equivariant maps $F_1, \\dots, F_k$ and $f$ is invariant, then\n",
    "\\begin{align*}\n",
    "& f(F_k(F_{k-1}( \\cdots (F_2(F_1(g \\cdot x)) \\cdots ) = f(F_k(F_{k-1}( \\cdots (F_2(g \\cdot F_1(x)) \\cdots) \\\\\n",
    "& = \\cdots =  f(g \\cdot F_k(F_{k-1}( \\cdots (F_2(F_1(x)) \\cdots) = f(g \\cdot F_k(F_{k-1}( \\cdots (F_2(F_1(x)) \\cdots)\n",
    "\\end{align*}\n",
    "so this product is invariant.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c59e211",
   "metadata": {},
   "source": [
    "Building blocks we can use:\n",
    "* Linear G-equivariant layers: Linear maps $B: \\mathcal{X}(\\Omega,\\mathcal{W}) \\to \\mathcal{X}(\\Omega',\\mathcal{W})$ satisfying $B(g\\cdot x) = g\\cdot B(x)$.\n",
    "* Nonlinearity: Non-linearity applied pointwise $(\\sigma x)(\\omega) = \\sigma(x(\\omega))$.\n",
    "* Local pooling (coarsening)\n",
    "$P: \\mathcal{X}(\\Omega,\\mathcal{W}) \\to \\mathcal{X}(\\Omega',\\mathcal{W})$\n",
    "* $G$-invariant layer (global pooling): $A: \\mathcal{X}(\\Omega,\\mathcal{W}) \\to \\mathcal{Y}$ such that $A(g \\cdot x) = A(x)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cc79b9",
   "metadata": {},
   "source": [
    "Architecture | Domain $\\Omega$ | Symmetry group $G$\n",
    "-------------|-----------------|--------------------\n",
    "Deep Sets | Sets | Permuations $S_n$\n",
    "GNN | Graphs | Permuations $S_n$\n",
    "CNN | Grid | Translations\n",
    "Spherical CNN | Sphere | SO(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e198996d",
   "metadata": {},
   "source": [
    "### Example: Deep sets\n",
    "\n",
    "[Zaheer et al, 2017](https://papers.nips.cc/paper_files/paper/2017/hash/f22e4747da1aa27e363d86d40ff442fe-Abstract.html)\n",
    "\n",
    "\n",
    "Symmetries for sets: Permutations.\n",
    "\n",
    "\n",
    "Equivariant layer $B:(\\mathbb{R}^d)^n \\to (\\mathbb{R}^{m})^{n\\times m}$:\n",
    "$$\\begin{pmatrix}\n",
    "x_1 \\\\ x_2 \\\\ x_3\\\\ \\cdots \\\\ x_n \n",
    "\\end{pmatrix} \\mapsto \n",
    "\\begin{pmatrix}\n",
    "\\psi(x_1) \\\\ \\psi(x_2) \\\\ \\psi(x_3)\\\\ \\cdots \\\\ \\psi(x_n) \n",
    "\\end{pmatrix}\n",
    "$$\n",
    "Global pooling\n",
    "$$\\begin{pmatrix}\n",
    "y_1 \\\\ y_2 \\\\ y_3\\\\ \\cdots \\\\ y_n \n",
    "\\end{pmatrix} \\mapsto \n",
    "\\phi(\\oplus y_i), \\qquad \\oplus_i y_i \\text{ permutation invariant from $n$ to $1$ variables}\n",
    "$$\n",
    "Examples\n",
    "$$\\oplus_i y_i = \\sum_i y_i ,\\qquad \\oplus_i y_i = \\max_i y_i \\qquad \\text{(taken coordinate-wise if multiple coordinates)}.$$\n",
    "\n",
    "$$\\text{Network architecture: psi-layer -> Nonlinearity -> psi-layer -> $\\cdots$ -> $\\oplus$-> phi-layer}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44bd947",
   "metadata": {},
   "source": [
    "**Let us look at a deep sets example in a separate notebook**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f67840",
   "metadata": {},
   "source": [
    "<span style=\"font-size:24px; color:blue\">\n",
    "Exercise: Which of the following functions are permutation invariant (can be used for $\\oplus$).\n",
    "  * Geometric mean\n",
    "    $$F(x_1,x_2 \\dots, x_n) = \\sqrt[n]{x_1 \\cdot x_2 \\cdots x_n }.$$\n",
    "  * The norm\n",
    "    $$F(x_1,x_2 \\dots, x_n) = \\|(x_1, \\dots,x_n\\|^2= \\sqrt{x_1^2 + x_2^2 + \\cdots + x_n^2 }.$$\n",
    "   * Difference max-min\n",
    "    $$F(x_1,x_2 \\dots, x_n) = \\max_i x_i - \\min_i x_i.$$\n",
    "    * Largest norm\n",
    "    $$F(x_1,x_2 \\dots, x_n) = argmax_{x \\in \\{x_i\\}} \\| x\\|.$$\n",
    "    * partial sum\n",
    "    $$F(x_1,x_2 \\dots, x_n) = \\sum_{i=1}^{n/2} x_i.$$\n",
    "    \n",
    " Even if they are invariant, are there any other reason to avoid them?\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed89531b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f235037a",
   "metadata": {},
   "source": [
    "<span style=\"font-size:24px; color:blue\">\n",
    "Exercise: If we allowed layers on the form\n",
    "$$\\begin{pmatrix}\n",
    "x_1 \\\\ x_2 \\\\ x_3\\\\ \\cdots \\\\ x_n \n",
    "\\end{pmatrix} \\mapsto \n",
    "\\begin{pmatrix}\n",
    "\\psi(x_{\\sigma(1)}) \\\\ \\psi(x_{\\sigma(2)}) \\\\ \\psi(x_{\\sigma(3)})\\\\ \\cdots \\\\ \\psi(x_{\\sigma(n)}) \n",
    "\\end{pmatrix} \\qquad \\text{where we choose any permutation $\\sigma$}\n",
    "$$\n",
    "are the layers still equivariant. Does it increase the expressitivity of the network?\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89e44f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edad1373",
   "metadata": {},
   "source": [
    "### Example: Graphs\n",
    "\n",
    "Next lectures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e6ca88",
   "metadata": {},
   "source": [
    "### Example Grids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20a6d51",
   "metadata": {},
   "source": [
    "Recall that we had *the cyclic group* $C_{n} = \\{ 0, 1, \\dots, n-1\\}$ with operation $+$ that is computed modulo $n$. For these grids, we have translations\n",
    "$$\\tau(p,q)[i,j] = [i+p \\bmod m,j+q \\bmod n], \\qquad (i,j), (p,q) \\in C_m \\times C_n.$$\n",
    "\n",
    "If we have a function on $x:C_m \\times C_n \\to \\mathbb{R}$\n",
    "$$(\\tau(p,q)x)[i,j] = x[i-p \\bmod m,j-q \\bmod n ].$$\n",
    "These are examples of 2d-grids. We can have grids in any dimension.\n",
    "\n",
    "Observation: Translation form **an abelian group**\n",
    "$$\\tau(p_1, q_1) \\cdot \\tau(p_2, q_2) = \\tau(p_1, q_1) \\circ \\tau(p_2, q_2) = \\tau(p_1+p_2 \\bmod m,q_1+q_2 \\bmod m).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cba3be4",
   "metadata": {},
   "source": [
    "<span style=\"font-size:24px; color:blue\"> Consider $\\Omega = C_m \\times C_n$, and $\\mathcal{X} = \\{ x: \\Omega \\to \\mathbb{R}\\}$, considered as 2d-arrays.\n",
    "Let $L: \\mathcal{X} \\to \\mathbb{R}$ be a linear map. All such linear maps can be written as\n",
    "   $$L(x) = \\sum_{i=1}^m \\sum_{j=1}^n x[i,j] M[i,j]\\qquad M \\in \\mathcal{X}.$$\n",
    "    Assume that $L(\\tau(p,q)x) = L(x)$ for any translation.\n",
    "    Explain that then we must have that $\\tau(p,q)M = M$ for any translation. What does $M$ look like? What can we conclude about linear functions invariant under translation.\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b48bfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d52dab",
   "metadata": {},
   "source": [
    "What about linear equivariant functions?\n",
    "\n",
    "**Theorem** Consider $\\Omega = C_m \\times C_n$, and $\\mathcal{X} = \\{ x: \\Omega \\to \\mathbb{R}\\}$, considered as 2d-arrays. Assume that $L: \\mathcal{X} \\to \\mathcal{X}$ is equivariant under translations. Then it is a convolution\n",
    "$$L(x)[i,j]  = \\sum_{p=1}^m \\sum_{q=1}^n x[i-p,j-q] M[p,q], \\qquad M\\in \\mathcal{X}.$$\n",
    "Note that by changing our $M$, we can also write\n",
    "$$L(x)[i,j]  = \\sum_{p=1}^m \\sum_{q=1}^n x[i+p,j+q] M[p,q], \\qquad M\\in \\mathcal{X},$$\n",
    "which is often what is computed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac397b0",
   "metadata": {},
   "source": [
    "<span style=\"font-size:24px; color:blue\"> Exercise: Consider the filter below that we used in the beginning. Can you understand its effect on images from the definition below? Explain how it works.\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5437288",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We have a convolution filter\n",
    "Filter = np.array([[0,-1,10,-1,0],[0,0,-1,0,0],[0,0,0,0,0],[0,0,0,0,0],[0,0,0,0,0]]) # Sharpens and moves 5 pixels up\n",
    "Filter = np.zeros([201,201])\n",
    "Filter[0,100]=10\n",
    "Filter[0,99]=-1\n",
    "Filter[0,101]=-1\n",
    "Filter[1,100]=-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bc0554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53d5593",
   "metadata": {},
   "source": [
    "Structure of CNNs that wants an invariant model\n",
    "* Convolutional layers that are equivariant.\n",
    "* Nonlinearity.\n",
    "* Pooling layers (often max-pooling)\n",
    "* Final part involves linear layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27331fa",
   "metadata": {},
   "source": [
    "**Let us look at an example**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500bfbd2",
   "metadata": {},
   "source": [
    "### Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e600882",
   "metadata": {},
   "source": [
    "Let us consider the following special case, to illustrate a more general framework. We want to consider $\\Omega = C_n \\times C_n$, with its signals $\\mathcal{X}$ being squared images. We want to be able to train a model on our images that is invariant under translations, but also under rotations that is a multiple of $\\frac{\\pi}{2}$ (90 degrees). We now make a larger group, consisting of:\n",
    "* translations: $\\tau(p,q)[i,j] = [i+p,j+q]$. (all additions are done modulo $n$)\n",
    "* rotations: $R_{\\pi/2} = R$, $R_{\\pi} = R^2$, $R_{3\\pi/2} = R^3$, action by\n",
    "$$R^r \\cdot [i,j] = R^j([i,j]-c)+c \\qquad \\text{$c$ center point, $r=0,1,2,3$.}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e6b979",
   "metadata": {},
   "source": [
    "<span style=\"font-size:24px; color:blue\">\n",
    "    Exercise: Does the definition of the action of $R^r$ make sense? What happens if $[i,j]=c$?\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108f0aab",
   "metadata": {},
   "source": [
    "Define $\\sigma([p,q], r)$ by\n",
    "$$\\sigma([p,q],r)[i,j] = \\tau(p,q) (R^r \\cdot [i,j]).$$\n",
    "Then\n",
    "$$\\sigma([p1,q1],r1) \\cdot \\sigma([p2,q2],r2) = \\sigma([p1,q1]+R^{r_1}[p2,q2], r_1+r_2).$$\n",
    "Can simplify this notation  to\n",
    "$$(a1,r1) \\cdot (a2,r2) = (a1+R^{r_1}a2, r_1+r_2), \\qquad aj =[pj,qj].$$\n",
    "\n",
    "\n",
    "We define a group $G$ of these maps. We want a model that is invariant under $G$, which means finding equivariant layers and an invariant global pooling layer.\n",
    "\n",
    "Let $\\mathcal{X}_G$ be signals on $G$. If $x \\in \\mathcal{X}$, we can consider it as an element in $\\mathcal{X}_G$ by\n",
    "$$x([p,q],r)= x[p,q].$$\n",
    "With all of this formalism at hand, we end up with these final questions:\n",
    "* What are invariant functions on $\\mathcal{X}_G$ with respect to the action of $G$ on itself?\n",
    "* What are equivariant functions on $\\mathcal{X}_G$ with respect to the action of $G$ on itself?\n",
    "The action of the group $G$ on $\\mathcal{X}_G$ is called *the regular representation*. We then have the following result.\n",
    "\n",
    "For invariance, we still have that sum and max are invariants."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0055e577",
   "metadata": {},
   "source": [
    "**Theorem: Convolutions is all you need**\n",
    "If $L: \\mathcal{X}_G \\to \\mathcal{X}_G$ be a linear equivariant map between regular representations. Then $L$ is **a group convolution**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2386e15",
   "metadata": {},
   "source": [
    "What is a group convolution? Usual convolution\n",
    "\\begin{align*}\n",
    "L(x)[i,j]  &= \\sum_{p=1}^m \\sum_{q=1}^n x[i-p,j-q] M[p,q] \\\\\n",
    "& = \\sum_{p=1}^m \\sum_{q=1}^n x[p,q] M[p-i,qj] = \\sum_{p=1}^m \\sum_{q=1}^n x[p,q] (\\tau(i,j)M)[p,q] .\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040d3cb6",
   "metadata": {},
   "source": [
    "Group convolution:\n",
    "\\begin{align*}\n",
    "L(x)(h)  &= \\sum_{g \\in G} x(g) (h \\cdot M)(g) \\\\\n",
    "&= \\sum_{g \\in G} x(g) M(h^{-1}g) .\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4759d69b",
   "metadata": {},
   "source": [
    "For our group $G$\n",
    "$$(a,r)^{-1} = (-R^{-r} a,-r),$$\n",
    "so\n",
    "$$L(x)(a,r) = \\sum_{a2 \\in C_n \\times C_n} \\sum_{r2 =0}^3 x(a2,r2)M(R^{-r}(a2-a),r2-r) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee8d64e",
   "metadata": {},
   "source": [
    "[Here is a paper implementing it for the datasets we have seen](https://tacocohen.wordpress.com/wp-content/uploads/2016/06/gcnn.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae947ea8",
   "metadata": {},
   "source": [
    "For example for other groups. [Here is an example for the sphere](https://arxiv.org/pdf/1801.10130v3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07123a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
