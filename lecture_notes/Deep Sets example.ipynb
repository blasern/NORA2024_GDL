{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "343b4c71",
   "metadata": {},
   "source": [
    "# Deep Sets example\n",
    "\n",
    "The dataset are samples from a 12-th order polynomial. The objective of the set will be to learn the polynomials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b509c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The packages we need\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602165a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset\n",
    "class PolynomialDataset(Dataset):\n",
    "    def __init__(self, num_samples=1000, set_size=10, order=12):\n",
    "        # Dataset with 1000 samples\n",
    "        # Each sample contain 10 points: Cannot match them perfectly\n",
    "        self.num_samples = num_samples\n",
    "        self.set_size = set_size\n",
    "        self.order = order\n",
    "        self.data = []\n",
    "        self.targets = []\n",
    "\n",
    "        for _ in range(num_samples):\n",
    "            coefficients = np.random.randn(order + 1)\n",
    "            #coefficients of the polynomial including zero order\n",
    "            \n",
    "            x = np.random.uniform(-1, 1, set_size)\n",
    "            # random samples\n",
    "            \n",
    "            y = np.polyval(coefficients, x)\n",
    "            # y-values corresponding to the coefficients\n",
    "            \n",
    "            self.data.append(torch.tensor(np.vstack((x, y)).T, dtype=torch.float32))\n",
    "            self.targets.append(torch.tensor(coefficients, dtype=torch.float32))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eddc4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We will use the psi to define the model\n",
    "\n",
    "class DeepSets(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(DeepSets, self).__init__()\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        self.phi = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply psi to each element in the set\n",
    "        psi_x = self.psi(x)\n",
    "        # Sum the outputs of psi\n",
    "        summed_psi_x = psi_x.sum(dim=1)\n",
    "        # Apply phi to the summed outputs\n",
    "        output = self.phi(summed_psi_x)\n",
    "        return output\n",
    "\n",
    "# Hyperparameters\n",
    "input_dim = 2\n",
    "hidden_dim = 64\n",
    "output_dim = 13\n",
    "num_samples = 1000\n",
    "set_size = 10\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "num_epochs = 250\n",
    "\n",
    "# Prepare the dataset and dataloader\n",
    "dataset = PolynomialDataset(num_samples=num_samples, set_size=set_size, order=output_dim-1)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Instantiate the model, loss function, and optimizer\n",
    "model = DeepSets(input_dim, hidden_dim, output_dim)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data, targets in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss / len(dataloader)}')\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "test_set, true_coefficients = dataset[0]  # Take the first sample from the dataset\n",
    "test_set = test_set.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "with torch.no_grad():\n",
    "    predicted_coefficients = model(test_set).squeeze().numpy()\n",
    "\n",
    "print(f'True Coefficients: {true_coefficients.numpy()}')\n",
    "print(f'Predicted Coefficients: {predicted_coefficients}')\n",
    "\n",
    "# Generate points for plotting the true and predicted polynomials\n",
    "x_plot = np.linspace(-1, 1, 400)\n",
    "true_y_plot = np.polyval(true_coefficients.numpy(), x_plot)\n",
    "predicted_y_plot = np.polyval(predicted_coefficients, x_plot)\n",
    "\n",
    "# Plot the points and polynomials\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(test_set.squeeze()[:, 0].numpy(), test_set.squeeze()[:, 1].numpy(), color='blue', label='Data Points')\n",
    "plt.plot(x_plot, true_y_plot, color='green', label='True Polynomial', linewidth=2)\n",
    "plt.plot(x_plot, predicted_y_plot, color='red', label='Predicted Polynomial', linestyle='dashed', linewidth=2)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('True vs Predicted Polynomial')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
