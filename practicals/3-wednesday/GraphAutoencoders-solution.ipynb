{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f26c0da-31b9-480b-a817-f3da950c9a21",
   "metadata": {},
   "source": [
    "### Graph Auto-Encoders\n",
    "\n",
    "In this exercise, we will implement an GCN based autoencoder to learn better embeddings to perform dimensionality reduction. \n",
    "\n",
    "Autoencoders such as the ones we will implement today can be thought to be non-linear PCAs. \n",
    "\n",
    "We begin by preparing the data:\n",
    "\n",
    "1. Load the tensor data for CHILI-Challenge and labels\n",
    "2. Create the Torch dataset, dataloaders\n",
    "3. Complete the autoencoder forward call.\n",
    "4. Visualize the low dimensional embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82477fca-45b3-4661-95ec-a7cf504aaa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import download_url, extract_zip\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.loader import DataLoader\n",
    "import pdb\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929da687",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loc = './Data'\n",
    "if not Path(data_loc).exists():\n",
    "    Path(data_loc).mkdir()\n",
    "else:\n",
    "    print(data_loc, 'exists!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce659316",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://sid.erda.dk/share_redirect/h7plnJoaYR/CHILI-Challenge.zip'\n",
    "dataset_name = 'CHILI-Challenge'\n",
    "\n",
    "if not Path(data_loc+'/'+dataset_name+'.zip').exists():\n",
    "    print('Data not locally found. Downloading...')\n",
    "    path = download_url(url,data_loc)\n",
    "    print('Extracting data...')\n",
    "    extract_zip(path, data_loc)\n",
    "    print('Done!')\n",
    "else:\n",
    "    print('Data found at '+data_loc)\n",
    "    data_loc += '/'+dataset_name\n",
    "    print(os.listdir(data_loc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17720059-b24a-4666-9f5a-92f3d2db0def",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(GraphAutoencoder, self).__init__()\n",
    "\n",
    "        # Encoder layers\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, latent_dim)\n",
    "\n",
    "        # Decoder layers\n",
    "        self.deconv1 = GCNConv(latent_dim, hidden_dim)\n",
    "        self.deconv2 = GCNConv(hidden_dim, input_dim)\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        z = (self.conv2(x, edge_index))\n",
    "        \n",
    "        return z\n",
    "\n",
    "    def decode(self, z, edge_index):\n",
    "        z = F.relu(self.deconv1(z, edge_index))\n",
    "        xHat = self.deconv2(z, edge_index)\n",
    "        return xHat\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        z = self.encode(x, edge_index) # obtain latent representations from encoder\n",
    "        x_hat = self.decode(z,edge_index) # obtain reconstructed node features from decoder\n",
    "        return x_hat, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a664c46d-c7c8-4238-b440-9e864a4834cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torch.load('Data/CHILI-Challenge/train.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6abacb-e382-4804-a3eb-9645a66873cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214100f1-5c05-48d5-9408-854f18cbce53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "input_dim = 10  # Input node feature dimension\n",
    "hidden_dim = 32  # Hidden layer dimension\n",
    "latent_dim = 2  # Latent space dimension\n",
    "B =16\n",
    "num_epochs = 10\n",
    "train_loader = DataLoader(train_set,batch_size=B)\n",
    "\n",
    "model = GraphAutoencoder(input_dim, hidden_dim, latent_dim)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Assuming you have a molecular graph dataset with node features x and edge_index\n",
    "# Iterate over your dataset and train the model\n",
    "for epoch in range(num_epochs):\n",
    "    for data in train_loader:\n",
    "        x, edge_index = torch.cat((data.x, data.pos_abs,data.pos_frac),dim=1), data.edge_index\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        x_hat, z = model(x, edge_index)\n",
    "        loss = F.mse_loss(x_hat, x)  # Mean Squared Error loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch {epoch + 1}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d806292-7a07-413c-8fff-4ee15b86751e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Low dimensions using handcrafted features\n",
    "feature_1 = [t.x.mean() for t in train_set] #\n",
    "feature_2 = [t.x.shape[0] for t in train_set]#\n",
    "labels = [t.y['crystal_type_number'] for t in train_set] #\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.scatter(feature_1,feature_2,c=labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c885441-d718-4ed1-a521-3c538e3af257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Low dimensional features using learnt features\n",
    "embeddings = []\n",
    "B = 1\n",
    "train_loader = DataLoader(train_set,batch_size=B)\n",
    "with torch.no_grad():\n",
    "    for data in train_loader:\n",
    "            x, edge_index = torch.cat((data.x, data.pos_abs,data.pos_frac),dim=1), data.edge_index\n",
    "            _, z = model(x, edge_index)\n",
    "            embeddings.append(z.mean(0))\n",
    "embeddings = torch.stack(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69011f5a-0fba-4adb-b9df-6b8178e27a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.scatter(embeddings[:,0],embeddings[:,1],c=labels)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
